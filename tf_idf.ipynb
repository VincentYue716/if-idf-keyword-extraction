{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% read a csv file and convert to string list\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_column(csv_path, column_name):\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "    return df[column_name].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "def extract_topn_from_vector(feature_name_list, sorted_item_list, topn=10):\n",
    "    \"\"\"\n",
    "    get the feature names and tf-idf score of top n items\n",
    "    \"\"\"\n",
    "\n",
    "    # use only topn items from vector\n",
    "    sorted_item_list = sorted_item_list[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_item_list:\n",
    "\n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_name_list[idx])\n",
    "\n",
    "    # create a tuples of feature,score\n",
    "    # results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# get the weibo contents\n",
    "weibo_contents = read_csv_column('./trump/processed_trump.csv', '微博正文')\n",
    "\n",
    "# ignore words that appear in 85% of documents\n",
    "cv=CountVectorizer(max_df=0.85, max_features=10000)\n",
    "word_count_vector=cv.fit_transform(weibo_contents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% create a vocabulary of words\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "['但特朗普', '不知', '知道', '说话', '创业', '平均', '股价', '2018年', '国庆', '本来']"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(weibo_contents[0]))\n",
    "list(cv.vocabulary_.keys())[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% look at 10 words from the vocabulary\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "TfidfTransformer()"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% compute the IDF values\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "trump1_content = read_csv_column('./trump/trump_10.csv', '微博正文')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% computing TF-IDF and extracting keywords\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keywords\n",
      "新冠 0.329\n",
      "美国 0.272\n",
      "哈哈哈 0.255\n",
      "确诊 0.231\n",
      "总统 0.197\n",
      "夫妇 0.188\n",
      "检测 0.146\n",
      "视频 0.144\n",
      "病毒 0.137\n",
      "阳性 0.127\n",
      "感染 0.127\n",
      "白宫 0.126\n",
      "朗普 0.125\n",
      "拜登 0.122\n",
      "接受 0.116\n",
      "辩论 0.115\n",
      "大选 0.114\n",
      "症状 0.111\n",
      "竞选 0.11\n",
      "治疗 0.108\n"
     ]
    }
   ],
   "source": [
    "item = ''\n",
    "for i in range(len(trump1_content)):\n",
    "    item = item + trump1_content[i]\n",
    "# item = trump1_content[1]\n",
    "# generate tf-idf for the given document\n",
    "tf_idf_vector = tfidf_transformer.transform(cv.transform([item]))\n",
    "\n",
    "# sort the tf-idf vectors by descending order of scores\n",
    "sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "# extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items, 20)\n",
    "\n",
    "# now print the results\n",
    "# print(\"\\n=====Doc=====\")\n",
    "# print(period_contents)\n",
    "print(\"\\nKeywords\")\n",
    "for k in keywords:\n",
    "    print(k, keywords[k])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}