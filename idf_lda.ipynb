{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_column(csv_path, column_name):\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "    return df[column_name].tolist()\n",
    "\n",
    "def read_csv_with_weight(csv_path):\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "    # 转发数,评论数,点赞数\n",
    "    comments = df['评论数'].tolist()\n",
    "    reposts = df['转发数'].tolist()\n",
    "    likes = df['点赞数'].tolist()\n",
    "    weibos = df['微博正文'].tolist()\n",
    "    results = []\n",
    "\n",
    "    for row in range(len(weibos)):\n",
    "        if comments[row] + reposts[row] + likes[row] > 10:\n",
    "            results.append(weibos[row])\n",
    "\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% read a csv file and convert to string list\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "contents = read_csv_column('./trump/preprocessed_v2.csv', '微博正文')\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for content in contents:\n",
    "    content = content.split()\n",
    "    new_list.append(content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 27 (\"说话\") appears 2 time.\n",
      "Word 50 (\"时间\") appears 2 time.\n",
      "Word 122 (\"关注\") appears 1 time.\n",
      "Word 198 (\"30日\") appears 1 time.\n",
      "Word 199 (\"BBC\") appears 1 time.\n",
      "Word 200 (\"专家\") appears 1 time.\n",
      "Word 201 (\"人身\") appears 1 time.\n",
      "Word 202 (\"可笑\") appears 1 time.\n",
      "Word 203 (\"回应\") appears 1 time.\n",
      "Word 204 (\"大会\") appears 1 time.\n",
      "Word 205 (\"对此\") appears 1 time.\n",
      "Word 206 (\"对话\") appears 1 time.\n",
      "Word 207 (\"少女\") appears 1 time.\n",
      "Word 208 (\"接受\") appears 1 time.\n",
      "Word 209 (\"推特\") appears 1 time.\n",
      "Word 210 (\"攻击\") appears 1 time.\n",
      "Word 211 (\"死亡\") appears 1 time.\n",
      "Word 212 (\"气候\") appears 1 time.\n",
      "Word 213 (\"浪费\") appears 2 time.\n",
      "Word 214 (\"焦点\") appears 1 time.\n",
      "Word 215 (\"狠狠\") appears 1 time.\n",
      "Word 216 (\"环保\") appears 1 time.\n",
      "Word 217 (\"瑞典\") appears 1 time.\n",
      "Word 218 (\"生活\") appears 1 time.\n",
      "Word 219 (\"科学家\") appears 1 time.\n",
      "Word 220 (\"联合国\") appears 1 time.\n",
      "Word 221 (\"讽刺\") appears 1 time.\n",
      "Word 222 (\"采访\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "'''\n",
    "Create a dictionary from 'processed_docs' containing the number of times a word appears\n",
    "in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
    "'''\n",
    "\n",
    "dictionary = Dictionary(new_list)\n",
    "\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.85, keep_n=10000)\n",
    "\n",
    "'''\n",
    "Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to 'bow_corpus'\n",
    "'''\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in new_list]\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0],\n",
    "                                                     dictionary[bow_doc_x[i][0]],\n",
    "                                                     bow_doc_x[i][1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFull\u001B[0m                                      Traceback (most recent call last)",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/gensim/models/ldamulticore.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, corpus, chunks_as_numpy)\u001B[0m\n\u001B[1;32m    291\u001B[0m                     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                         \u001B[0mjob_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk_no\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mblock\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    293\u001B[0m                         \u001B[0mqueue_size\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/multiprocessing/queues.py\u001B[0m in \u001B[0;36mput\u001B[0;34m(self, obj, block, timeout)\u001B[0m\n\u001B[1;32m     83\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mFull\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFull\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-5715d091981f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m '''\n\u001B[1;32m     13\u001B[0m \u001B[0;31m# TODO\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m lda_model = LdaMulticore(bow_corpus,\n\u001B[0m\u001B[1;32m     15\u001B[0m                                \u001B[0mnum_topics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m                                \u001B[0mid2word\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdictionary\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/gensim/models/ldamulticore.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001B[0m\n\u001B[1;32m    177\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"auto-tuning alpha not implemented in multicore LDA; use plain LdaModel.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 179\u001B[0;31m         super(LdaMulticore, self).__init__(\n\u001B[0m\u001B[1;32m    180\u001B[0m             \u001B[0mcorpus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcorpus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_topics\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_topics\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m             \u001B[0mid2word\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mid2word\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mchunksize\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpasses\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpasses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meta\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meta\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/gensim/models/ldamodel.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001B[0m\n\u001B[1;32m    517\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcorpus\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    518\u001B[0m             \u001B[0muse_numpy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatcher\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 519\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcorpus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunks_as_numpy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_numpy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    520\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    521\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minit_dir_prior\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprior\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/gensim/models/ldamulticore.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, corpus, chunks_as_numpy)\u001B[0m\n\u001B[1;32m    301\u001B[0m                         \u001B[0;31m# in case the input job queue is full, keep clearing the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m                         \u001B[0;31m# result queue, to make sure we don't deadlock\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 303\u001B[0;31m                         \u001B[0mprocess_result_queue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    304\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    305\u001B[0m                 \u001B[0mprocess_result_queue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/site-packages/gensim/models/ldamulticore.py\u001B[0m in \u001B[0;36mprocess_result_queue\u001B[0;34m(force)\u001B[0m\n\u001B[1;32m    266\u001B[0m             \"\"\"\n\u001B[1;32m    267\u001B[0m             \u001B[0mmerged_new\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 268\u001B[0;31m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mresult_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    269\u001B[0m                 \u001B[0mother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmerge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m                 \u001B[0mqueue_size\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/multiprocessing/queues.py\u001B[0m in \u001B[0;36mempty\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mempty\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 123\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfull\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/multiprocessing/connection.py\u001B[0m in \u001B[0;36mpoll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_readable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__enter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/multiprocessing/connection.py\u001B[0m in \u001B[0;36m_poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 424\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    425\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/multiprocessing/connection.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    930\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 931\u001B[0;31m                 \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    932\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    933\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfileobj\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevents\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/envs/nlp/lib/python3.8/selectors.py\u001B[0m in \u001B[0;36mselect\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m         \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 415\u001B[0;31m             \u001B[0mfd_event_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_selector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    416\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mInterruptedError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "\n",
    "# LDA mono-core -- fallback code in case LdaMulticore throws an error on your machine\n",
    "# lda_model = gensim.models.LdaModel(bow_corpus,\n",
    "#                                    num_topics = 10,\n",
    "#                                    id2word = dictionary,\n",
    "#                                    passes = 50)\n",
    "\n",
    "# LDA multicore\n",
    "'''\n",
    "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
    "'''\n",
    "# TODO\n",
    "lda_model = LdaMulticore(bow_corpus,\n",
    "                               num_topics = 100,\n",
    "                               id2word = dictionary,\n",
    "                               passes = 10,\n",
    "                               workers = 4)\n",
    "\n",
    "'''\n",
    "For each topic, we will explore the words occurring in that topic and its relative weight\n",
    "'''\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trump1_content = read_csv_with_weight('./trump/trump_1.csv')\n",
    "\n",
    "item = ''\n",
    "for i in range(len(trump1_content)):\n",
    "    item = item + trump1_content[i]\n",
    "unseen_document = item.split()\n",
    "\n",
    "bow_vector = dictionary.doc2bow(unseen_document)\n",
    "\n",
    "print(\"4月\\n\")\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 20)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}