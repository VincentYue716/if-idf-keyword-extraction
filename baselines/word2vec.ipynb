{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.cluster import KMeans\n",
    "import openpyxl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% read a csv file and convert to string list\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def read_csv_column(csv_path, column_name):\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "    return df[column_name].tolist()\n",
    "\n",
    "def get_top_words(index2word, k, word_centers, word_vectors):\n",
    "    tree = KDTree(word_vectors)\n",
    "# Closest points for each Cluster center is used to query the closest 20 points to it.\n",
    "    closest_points = [tree.query(np.reshape(x, (1, -1)), k = k) for x in word_centers]\n",
    "    closest_words_idxes = [x[1] for x in closest_points]\n",
    "# Word Index is queried for each position in the above array, and added to a Dictionary.\n",
    "    closest_words = {}\n",
    "    for index in range(0, len(closest_words_idxes)):\n",
    "        closest_words['Cluster #' + str(index)] = [index2word[j] for j in closest_words_idxes[index][0]]\n",
    "# A DataFrame is generated from the dictionary.\n",
    "    df = pd.DataFrame(closest_words)\n",
    "    df.index = df.index + 1\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = read_csv_column('../dataset/trump/trump01.csv', '微博正文')\n",
    "documents = []\n",
    "for content in contents:\n",
    "    content = content.split()\n",
    "    new_content = []\n",
    "    for i in content:\n",
    "        if len(i) != 1:\n",
    "            new_content.append(i)\n",
    "    documents.append(new_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-09 21:23:01,835 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2021-04-09 21:23:01,836 : INFO : collecting all words and their counts\n",
      "2021-04-09 21:23:01,837 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-04-09 21:23:01,905 : INFO : PROGRESS: at sentence #10000, processed 285434 words, keeping 24494 word types\n",
      "2021-04-09 21:23:01,959 : INFO : collected 36603 word types from a corpus of 552662 raw words and 18398 sentences\n",
      "2021-04-09 21:23:01,960 : INFO : Loading a fresh vocabulary\n",
      "2021-04-09 21:23:01,996 : INFO : effective_min_count=2 retains 18856 unique words (51% of original 36603, drops 17747)\n",
      "2021-04-09 21:23:01,996 : INFO : effective_min_count=2 leaves 534915 word corpus (96% of original 552662, drops 17747)\n",
      "2021-04-09 21:23:02,040 : INFO : deleting the raw counts dictionary of 36603 items\n",
      "2021-04-09 21:23:02,041 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2021-04-09 21:23:02,042 : INFO : downsampling leaves estimated 468958 word corpus (87.7% of prior 534915)\n",
      "2021-04-09 21:23:02,081 : INFO : estimated required memory for 18856 words and 150 dimensions: 32055200 bytes\n",
      "2021-04-09 21:23:02,082 : INFO : resetting layer weights\n",
      "2021-04-09 21:23:05,296 : INFO : training model with 10 workers on 18856 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2021-04-09 21:23:05,522 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-09 21:23:05,528 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-09 21:23:05,530 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-09 21:23:05,534 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-09 21:23:05,536 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-09 21:23:05,537 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-09 21:23:05,542 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-09 21:23:05,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-09 21:23:05,551 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-09 21:23:05,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-09 21:23:05,553 : INFO : EPOCH - 1 : training on 552662 raw words (468786 effective words) took 0.3s, 1867867 effective words/s\n",
      "2021-04-09 21:23:05,816 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-09 21:23:05,831 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-09 21:23:05,833 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-09 21:23:05,835 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-09 21:23:05,835 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-09 21:23:05,842 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-09 21:23:05,845 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-09 21:23:05,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-09 21:23:05,848 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-09 21:23:05,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-09 21:23:05,858 : INFO : EPOCH - 2 : training on 552662 raw words (468984 effective words) took 0.3s, 1596189 effective words/s\n",
      "2021-04-09 21:23:06,136 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-09 21:23:06,139 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-09 21:23:06,143 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-09 21:23:06,145 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-09 21:23:06,149 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-09 21:23:06,150 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-09 21:23:06,157 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-09 21:23:06,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-09 21:23:06,166 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-09 21:23:06,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-09 21:23:06,168 : INFO : EPOCH - 3 : training on 552662 raw words (469056 effective words) took 0.3s, 1562195 effective words/s\n",
      "2021-04-09 21:23:06,432 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-09 21:23:06,434 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-09 21:23:06,440 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-09 21:23:06,444 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-09 21:23:06,446 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-09 21:23:06,447 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-09 21:23:06,455 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-09 21:23:06,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-09 21:23:06,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-09 21:23:06,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-09 21:23:06,464 : INFO : EPOCH - 4 : training on 552662 raw words (468913 effective words) took 0.3s, 1645405 effective words/s\n",
      "2021-04-09 21:23:06,696 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-04-09 21:23:06,711 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-04-09 21:23:06,716 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-04-09 21:23:06,717 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-04-09 21:23:06,718 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-04-09 21:23:06,722 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-04-09 21:23:06,724 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-04-09 21:23:06,728 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-09 21:23:06,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-09 21:23:06,738 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-09 21:23:06,739 : INFO : EPOCH - 5 : training on 552662 raw words (469083 effective words) took 0.3s, 1770761 effective words/s\n",
      "2021-04-09 21:23:06,740 : INFO : training on a 2763310 raw words (2344822 effective words) took 1.4s, 1625144 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "# model.train(documents,total_examples=len(documents),epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#获取model里面的说有关键词\n",
    "vocab = model.wv.vocab\n",
    "print(type(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-34-5209c2fa48f0>:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n  word_vector.append(model[key])\n"
     ]
    }
   ],
   "source": [
    "keys=model.wv.vocab.keys()\n",
    "\n",
    "#获取词对于的词向量\n",
    "word_vector=[]\n",
    "for key in keys:\n",
    "    word_vector.append(model[key])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "#分类\n",
    "kMeans_clustering = KMeans(n_clusters=10, init='k-means++')\n",
    "clusters = kMeans_clustering.fit_predict(word_vector)\n",
    "centers = kMeans_clustering.cluster_centers_\n",
    "centroid_map = dict(zip(model.wv.index2word, clusters))\n",
    "# s = clf.fit(word_vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-36-4117ed6994a6>:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n  Z = model.wv.syn0\n"
     ]
    }
   ],
   "source": [
    "Z = model.wv.syn0\n",
    "top_words = get_top_words(model.wv.index2word, 20, centers, Z)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Cluster #0 Cluster #1 Cluster #2 Cluster #3 Cluster #4 Cluster #5  \\\n",
       "1          證券         维护        政治局         艺术       五角大楼         村庄   \n",
       "2          玩意         尊重       中共中央       绥靖主义        德黑兰         俊子   \n",
       "3        滚然而下         建立         委员         人性        伊斯兰    blog186   \n",
       "4          爬起         目的         前往         打造         军方         寂寞   \n",
       "5         成年人         条件        28日         落后         军官        007   \n",
       "6          趣味         各方        国务院         阶层         革命       海不扬波   \n",
       "7          手臂         做出         全国         中文         高官         秋野   \n",
       "8     taylors        进一步        30日         期權         首都        可可西   \n",
       "9          中外         寻求        牵头人         典型        指挥官         爽风   \n",
       "10         技術         缓和        10日         效果         复仇        斑马线   \n",
       "11         鸡汤         走向        13日        疫情O         杀死         美丽   \n",
       "12         从床         主权         刘鹤         愚蠢         部队         最佳   \n",
       "13         风度         挑战         2日         一大         炸死        新防线   \n",
       "14         营造        实际上         下午         找到       苏莱马尼         铮华   \n",
       "15         低级         呼吁         9日        星期六         击中         儿童   \n",
       "16         添加         机制         生日         未必         谴责         上海   \n",
       "17        商学院         战略        20日         耐心         策划      14653   \n",
       "18         废物         平衡         中央        常宁市        火箭弹         非洲   \n",
       "19         眼神         代表        29日         难度         杀害        博物馆   \n",
       "20         烦恼         旨在         上任         可爱         承认         华人   \n",
       "\n",
       "   Cluster #6 Cluster #7 Cluster #8   Cluster #9  \n",
       "1          空间        苏莱曼       民主党人         梅拉妮亚  \n",
       "2          需求    卡西姆苏莱马尼         团队           口令  \n",
       "3          大幅         讲述         指控           宁静  \n",
       "4          水平         数千         文件           出头  \n",
       "5          行业         口号         提交       Barron  \n",
       "6          财政         街头        共和党         大年初三  \n",
       "7          突破         哭泣         程序           箭头  \n",
       "8          调整         遭遇         证人           略带  \n",
       "9          趋势         报仇         议长          破天荒  \n",
       "10         产业         攻破         参院          EXO  \n",
       "11         短线         商量         表决           暴毙  \n",
       "12         能源         蓬佩        参议员           拉到  \n",
       "13         下降         开会        修正案  AlfredRag布偶  \n",
       "14        农产品         确认        佩洛西           摸摸  \n",
       "15        制造业         干掉         传唤           时尚  \n",
       "16         消费         家乡         辩护          同性恋  \n",
       "17         涨幅         可怕         辩论           普法  \n",
       "18         高位         互怼         投票           柯基  \n",
       "19         服务         家属         法院           防相  \n",
       "20         生产        环球网        博尔顿           低落  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster #0</th>\n      <th>Cluster #1</th>\n      <th>Cluster #2</th>\n      <th>Cluster #3</th>\n      <th>Cluster #4</th>\n      <th>Cluster #5</th>\n      <th>Cluster #6</th>\n      <th>Cluster #7</th>\n      <th>Cluster #8</th>\n      <th>Cluster #9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>證券</td>\n      <td>维护</td>\n      <td>政治局</td>\n      <td>艺术</td>\n      <td>五角大楼</td>\n      <td>村庄</td>\n      <td>空间</td>\n      <td>苏莱曼</td>\n      <td>民主党人</td>\n      <td>梅拉妮亚</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>玩意</td>\n      <td>尊重</td>\n      <td>中共中央</td>\n      <td>绥靖主义</td>\n      <td>德黑兰</td>\n      <td>俊子</td>\n      <td>需求</td>\n      <td>卡西姆苏莱马尼</td>\n      <td>团队</td>\n      <td>口令</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>滚然而下</td>\n      <td>建立</td>\n      <td>委员</td>\n      <td>人性</td>\n      <td>伊斯兰</td>\n      <td>blog186</td>\n      <td>大幅</td>\n      <td>讲述</td>\n      <td>指控</td>\n      <td>宁静</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>爬起</td>\n      <td>目的</td>\n      <td>前往</td>\n      <td>打造</td>\n      <td>军方</td>\n      <td>寂寞</td>\n      <td>水平</td>\n      <td>数千</td>\n      <td>文件</td>\n      <td>出头</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>成年人</td>\n      <td>条件</td>\n      <td>28日</td>\n      <td>落后</td>\n      <td>军官</td>\n      <td>007</td>\n      <td>行业</td>\n      <td>口号</td>\n      <td>提交</td>\n      <td>Barron</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>趣味</td>\n      <td>各方</td>\n      <td>国务院</td>\n      <td>阶层</td>\n      <td>革命</td>\n      <td>海不扬波</td>\n      <td>财政</td>\n      <td>街头</td>\n      <td>共和党</td>\n      <td>大年初三</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>手臂</td>\n      <td>做出</td>\n      <td>全国</td>\n      <td>中文</td>\n      <td>高官</td>\n      <td>秋野</td>\n      <td>突破</td>\n      <td>哭泣</td>\n      <td>程序</td>\n      <td>箭头</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>taylors</td>\n      <td>进一步</td>\n      <td>30日</td>\n      <td>期權</td>\n      <td>首都</td>\n      <td>可可西</td>\n      <td>调整</td>\n      <td>遭遇</td>\n      <td>证人</td>\n      <td>略带</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>中外</td>\n      <td>寻求</td>\n      <td>牵头人</td>\n      <td>典型</td>\n      <td>指挥官</td>\n      <td>爽风</td>\n      <td>趋势</td>\n      <td>报仇</td>\n      <td>议长</td>\n      <td>破天荒</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>技術</td>\n      <td>缓和</td>\n      <td>10日</td>\n      <td>效果</td>\n      <td>复仇</td>\n      <td>斑马线</td>\n      <td>产业</td>\n      <td>攻破</td>\n      <td>参院</td>\n      <td>EXO</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>鸡汤</td>\n      <td>走向</td>\n      <td>13日</td>\n      <td>疫情O</td>\n      <td>杀死</td>\n      <td>美丽</td>\n      <td>短线</td>\n      <td>商量</td>\n      <td>表决</td>\n      <td>暴毙</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>从床</td>\n      <td>主权</td>\n      <td>刘鹤</td>\n      <td>愚蠢</td>\n      <td>部队</td>\n      <td>最佳</td>\n      <td>能源</td>\n      <td>蓬佩</td>\n      <td>参议员</td>\n      <td>拉到</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>风度</td>\n      <td>挑战</td>\n      <td>2日</td>\n      <td>一大</td>\n      <td>炸死</td>\n      <td>新防线</td>\n      <td>下降</td>\n      <td>开会</td>\n      <td>修正案</td>\n      <td>AlfredRag布偶</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>营造</td>\n      <td>实际上</td>\n      <td>下午</td>\n      <td>找到</td>\n      <td>苏莱马尼</td>\n      <td>铮华</td>\n      <td>农产品</td>\n      <td>确认</td>\n      <td>佩洛西</td>\n      <td>摸摸</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>低级</td>\n      <td>呼吁</td>\n      <td>9日</td>\n      <td>星期六</td>\n      <td>击中</td>\n      <td>儿童</td>\n      <td>制造业</td>\n      <td>干掉</td>\n      <td>传唤</td>\n      <td>时尚</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>添加</td>\n      <td>机制</td>\n      <td>生日</td>\n      <td>未必</td>\n      <td>谴责</td>\n      <td>上海</td>\n      <td>消费</td>\n      <td>家乡</td>\n      <td>辩护</td>\n      <td>同性恋</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>商学院</td>\n      <td>战略</td>\n      <td>20日</td>\n      <td>耐心</td>\n      <td>策划</td>\n      <td>14653</td>\n      <td>涨幅</td>\n      <td>可怕</td>\n      <td>辩论</td>\n      <td>普法</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>废物</td>\n      <td>平衡</td>\n      <td>中央</td>\n      <td>常宁市</td>\n      <td>火箭弹</td>\n      <td>非洲</td>\n      <td>高位</td>\n      <td>互怼</td>\n      <td>投票</td>\n      <td>柯基</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>眼神</td>\n      <td>代表</td>\n      <td>29日</td>\n      <td>难度</td>\n      <td>杀害</td>\n      <td>博物馆</td>\n      <td>服务</td>\n      <td>家属</td>\n      <td>法院</td>\n      <td>防相</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>烦恼</td>\n      <td>旨在</td>\n      <td>上任</td>\n      <td>可爱</td>\n      <td>承认</td>\n      <td>华人</td>\n      <td>生产</td>\n      <td>环球网</td>\n      <td>博尔顿</td>\n      <td>低落</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "top_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0a38b35b77e6756a055eaa8a5c714418c79b2c1847796cd1ba287d8719b86b0a5",
   "display_name": "Python 3.8.8 64-bit ('nlp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}