{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% read a csv file and convert to string list\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_column(csv_path, column_name):\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8', low_memory=False)\n",
    "    return df[column_name].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "contents = read_csv_column('./trump/processed_trump.csv', '微博正文')\n",
    "\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for content in contents:\n",
    "    content = content.split()\n",
    "    new_content = []\n",
    "    for i in content:\n",
    "        if len(i) != 1:\n",
    "            new_content.append(i)\n",
    "    new_list.append(new_content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 143 (\"关注\") appears 1 time.\n",
      "Word 250 (\"30日\") appears 1 time.\n",
      "Word 251 (\"BBC\") appears 1 time.\n",
      "Word 252 (\"专家\") appears 1 time.\n",
      "Word 253 (\"今年\") appears 1 time.\n",
      "Word 254 (\"凝视\") appears 1 time.\n",
      "Word 255 (\"可笑\") appears 1 time.\n",
      "Word 256 (\"回应\") appears 1 time.\n",
      "Word 257 (\"多次\") appears 1 time.\n",
      "Word 258 (\"大会\") appears 1 time.\n",
      "Word 259 (\"天下\") appears 1 time.\n",
      "Word 260 (\"对话\") appears 1 time.\n",
      "Word 261 (\"少女\") appears 1 time.\n",
      "Word 262 (\"当时\") appears 1 time.\n",
      "Word 263 (\"接受\") appears 1 time.\n",
      "Word 264 (\"攻击\") appears 1 time.\n",
      "Word 265 (\"显然\") appears 1 time.\n",
      "Word 266 (\"来说\") appears 1 time.\n",
      "Word 267 (\"根本\") appears 1 time.\n",
      "Word 268 (\"格里塔\") appears 5 time.\n",
      "Word 269 (\"正常\") appears 1 time.\n",
      "Word 270 (\"死亡\") appears 1 time.\n",
      "Word 271 (\"气候\") appears 1 time.\n",
      "Word 272 (\"浪费\") appears 2 time.\n",
      "Word 273 (\"焦点\") appears 1 time.\n",
      "Word 274 (\"狠狠\") appears 1 time.\n",
      "Word 275 (\"环保\") appears 1 time.\n",
      "Word 276 (\"瑞典\") appears 1 time.\n",
      "Word 277 (\"生活\") appears 1 time.\n",
      "Word 278 (\"看来\") appears 1 time.\n",
      "Word 279 (\"科学家\") appears 1 time.\n",
      "Word 280 (\"联合国\") appears 1 time.\n",
      "Word 281 (\"讽刺\") appears 1 time.\n",
      "Word 282 (\"采访\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create a dictionary from 'processed_docs' containing the number of times a word appears\n",
    "in the training set using gensim.corpora.Dictionary and call it 'dictionary'\n",
    "'''\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(new_list)\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)\n",
    "\n",
    "'''\n",
    "Create the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\n",
    "words and how many times those words appear. Save this to 'bow_corpus'\n",
    "'''\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in new_list]\n",
    "\n",
    "document_num = 20\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0],\n",
    "                                                     dictionary[bow_doc_x[i][0]],\n",
    "                                                     bow_doc_x[i][1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.031*\"肺炎\" + 0.030*\"死亡\" + 0.025*\"病例\" + 0.023*\"疫苗\" + 0.016*\"人数\" + 0.013*\"福奇\" + 0.012*\"中心\" + 0.012*\"专家\" + 0.010*\"数据\" + 0.010*\"可能\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.012*\"朗普\" + 0.011*\"知道\" + 0.009*\"没有\" + 0.008*\"网友\" + 0.006*\"川普\" + 0.006*\"现在\" + 0.006*\"觉得\" + 0.006*\"世界\" + 0.006*\"记者\" + 0.005*\"看看\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.027*\"美元\" + 0.015*\"市场\" + 0.013*\"字节\" + 0.013*\"跳动\" + 0.012*\"经济\" + 0.012*\"关税\" + 0.008*\"刺激\" + 0.007*\"人民网\" + 0.007*\"指数\" + 0.007*\"黄金\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.013*\"可能\" + 0.012*\"问题\" + 0.010*\"国家\" + 0.010*\"没有\" + 0.008*\"围观\" + 0.008*\"已经\" + 0.008*\"世界\" + 0.008*\"现在\" + 0.007*\"经济\" + 0.006*\"政治\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.024*\"白宫\" + 0.020*\"报道\" + 0.017*\"当地\" + 0.015*\"TikTok\" + 0.014*\"竞选\" + 0.010*\"集会\" + 0.010*\"媒体\" + 0.010*\"纽约\" + 0.009*\"活动\" + 0.007*\"政府\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.023*\"疗法\" + 0.021*\"发烧\" + 0.021*\"巴马\" + 0.020*\"医生\" + 0.014*\"举报\" + 0.009*\"失职\" + 0.009*\"治疗\" + 0.009*\"见闻\" + 0.008*\"环球\" + 0.008*\"出现\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.062*\"哈哈哈\" + 0.017*\"外交部\" + 0.014*\"国际\" + 0.013*\"美方\" + 0.013*\"伊朗\" + 0.013*\"国家\" + 0.011*\"蓬佩奥\" + 0.011*\"回应\" + 0.010*\"中方\" + 0.010*\"组织\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.028*\"微信\" + 0.028*\"公司\" + 0.020*\"企业\" + 0.019*\"政府\" + 0.018*\"交易\" + 0.018*\"禁止\" + 0.017*\"行政\" + 0.014*\"华为\" + 0.013*\"禁令\" + 0.009*\"命令\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.056*\"拜登\" + 0.054*\"大选\" + 0.027*\"辩论\" + 0.026*\"深圳\" + 0.020*\"民主党\" + 0.019*\"市府\" + 0.018*\"除恶\" + 0.017*\"竞选\" + 0.017*\"投票\" + 0.017*\"政府\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.069*\"确诊\" + 0.041*\"检测\" + 0.033*\"夫妇\" + 0.029*\"感染\" + 0.026*\"口罩\" + 0.026*\"阳性\" + 0.021*\"接受\" + 0.020*\"症状\" + 0.019*\"朗普\" + 0.017*\"治疗\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA mono-core -- fallback code in case LdaMulticore throws an error on your machine\n",
    "# lda_model = gensim.models.LdaModel(bow_corpus,\n",
    "#                                    num_topics = 10,\n",
    "#                                    id2word = dictionary,\n",
    "#                                    passes = 50)\n",
    "\n",
    "# LDA multicore\n",
    "'''\n",
    "Train your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n",
    "'''\n",
    "# TODO\n",
    "lda_model =  gensim.models.LdaMulticore(bow_corpus,\n",
    "                                   num_topics = 10,\n",
    "                                   id2word = dictionary,\n",
    "                                   passes = 10,\n",
    "                                   workers = 3)\n",
    "\n",
    "'''\n",
    "For each topic, we will explore the words occurring in that topic and its relative weight\n",
    "'''\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.20569856464862823\t Topic: 0.069*\"确诊\" + 0.041*\"检测\" + 0.033*\"夫妇\" + 0.029*\"感染\" + 0.026*\"口罩\" + 0.026*\"阳性\" + 0.021*\"接受\" + 0.020*\"症状\" + 0.019*\"朗普\" + 0.017*\"治疗\" + 0.014*\"白宫\" + 0.013*\"抗体\" + 0.013*\"医院\" + 0.010*\"鸡尾酒\" + 0.010*\"助理\" + 0.010*\"出现\" + 0.010*\"良好\" + 0.010*\"隔离\" + 0.009*\"医疗\" + 0.008*\"康复\"\n",
      "Score: 0.14996275305747986\t Topic: 0.013*\"可能\" + 0.012*\"问题\" + 0.010*\"国家\" + 0.010*\"没有\" + 0.008*\"围观\" + 0.008*\"已经\" + 0.008*\"世界\" + 0.008*\"现在\" + 0.007*\"经济\" + 0.006*\"政治\" + 0.006*\"认为\" + 0.005*\"政府\" + 0.004*\"连任\" + 0.004*\"回答\" + 0.004*\"政策\" + 0.004*\"这种\" + 0.004*\"希望\" + 0.004*\"全球\" + 0.004*\"中美\" + 0.004*\"价值\"\n",
      "Score: 0.14765140414237976\t Topic: 0.024*\"白宫\" + 0.020*\"报道\" + 0.017*\"当地\" + 0.015*\"TikTok\" + 0.014*\"竞选\" + 0.010*\"集会\" + 0.010*\"媒体\" + 0.010*\"纽约\" + 0.009*\"活动\" + 0.007*\"政府\" + 0.007*\"接受\" + 0.007*\"抗议\" + 0.007*\"举行\" + 0.006*\"联邦\" + 0.006*\"记者\" + 0.006*\"进行\" + 0.005*\"华盛顿\" + 0.005*\"梅拉尼娅\" + 0.005*\"顾问\" + 0.005*\"采访\"\n",
      "Score: 0.10504915565252304\t Topic: 0.012*\"朗普\" + 0.011*\"知道\" + 0.009*\"没有\" + 0.008*\"网友\" + 0.006*\"川普\" + 0.006*\"现在\" + 0.006*\"觉得\" + 0.006*\"世界\" + 0.006*\"记者\" + 0.005*\"看看\" + 0.005*\"喜欢\" + 0.005*\"印度\" + 0.005*\"看到\" + 0.005*\"今天\" + 0.005*\"演讲\" + 0.005*\"起来\" + 0.005*\"相信\" + 0.004*\"第一\" + 0.004*\"非常\" + 0.004*\"大家\"\n",
      "Score: 0.10302509367465973\t Topic: 0.056*\"拜登\" + 0.054*\"大选\" + 0.027*\"辩论\" + 0.026*\"深圳\" + 0.020*\"民主党\" + 0.019*\"市府\" + 0.018*\"除恶\" + 0.017*\"竞选\" + 0.017*\"投票\" + 0.017*\"政府\" + 0.016*\"候选人\" + 0.016*\"选举\" + 0.015*\"共和党\" + 0.013*\"势力\" + 0.012*\"提名\" + 0.012*\"大法官\" + 0.009*\"连任\" + 0.009*\"当选\" + 0.009*\"发布\" + 0.009*\"发生\"\n",
      "Score: 0.08241119235754013\t Topic: 0.027*\"美元\" + 0.015*\"市场\" + 0.013*\"字节\" + 0.013*\"跳动\" + 0.012*\"经济\" + 0.012*\"关税\" + 0.008*\"刺激\" + 0.007*\"人民网\" + 0.007*\"指数\" + 0.007*\"黄金\" + 0.006*\"计划\" + 0.006*\"法案\" + 0.006*\"公安\" + 0.006*\"股市\" + 0.006*\"贸易\" + 0.006*\"办事\" + 0.006*\"市委\" + 0.006*\"数据\" + 0.005*\"签署\" + 0.005*\"全球\"\n",
      "Score: 0.06972664594650269\t Topic: 0.023*\"疗法\" + 0.021*\"发烧\" + 0.021*\"巴马\" + 0.020*\"医生\" + 0.014*\"举报\" + 0.009*\"失职\" + 0.009*\"治疗\" + 0.009*\"见闻\" + 0.008*\"环球\" + 0.008*\"出现\" + 0.007*\"起诉\" + 0.006*\"普京\" + 0.006*\"爱国\" + 0.006*\"大学\" + 0.005*\"稀土\" + 0.005*\"侄女\" + 0.005*\"曝光\" + 0.005*\"分享\" + 0.005*\"华裔\" + 0.005*\"炮轰\"\n",
      "Score: 0.05344265699386597\t Topic: 0.031*\"肺炎\" + 0.030*\"死亡\" + 0.025*\"病例\" + 0.023*\"疫苗\" + 0.016*\"人数\" + 0.013*\"福奇\" + 0.012*\"中心\" + 0.012*\"专家\" + 0.010*\"数据\" + 0.010*\"可能\" + 0.009*\"感染\" + 0.009*\"白宫\" + 0.009*\"控制\" + 0.008*\"全球\" + 0.008*\"卫生\" + 0.008*\"消防\" + 0.007*\"惨案\" + 0.007*\"累计\" + 0.006*\"当地\" + 0.006*\"超过\"\n",
      "Score: 0.049884550273418427\t Topic: 0.062*\"哈哈哈\" + 0.017*\"外交部\" + 0.014*\"国际\" + 0.013*\"美方\" + 0.013*\"伊朗\" + 0.013*\"国家\" + 0.011*\"蓬佩奥\" + 0.011*\"回应\" + 0.010*\"中方\" + 0.010*\"组织\" + 0.009*\"关系\" + 0.009*\"俄罗斯\" + 0.009*\"发言人\" + 0.008*\"军事\" + 0.008*\"美军\" + 0.008*\"安全\" + 0.008*\"赵立坚\" + 0.008*\"香港\" + 0.008*\"威胁\" + 0.007*\"TikTok\"\n",
      "Score: 0.033147938549518585\t Topic: 0.028*\"微信\" + 0.028*\"公司\" + 0.020*\"企业\" + 0.019*\"政府\" + 0.018*\"交易\" + 0.018*\"禁止\" + 0.017*\"行政\" + 0.014*\"华为\" + 0.013*\"禁令\" + 0.009*\"命令\" + 0.009*\"进行\" + 0.009*\"加拿大\" + 0.009*\"45\" + 0.009*\"业务\" + 0.009*\"回应\" + 0.008*\"英国\" + 0.008*\"要求\" + 0.008*\"宣布\" + 0.008*\"科技\" + 0.007*\"安全\"\n"
     ]
    }
   ],
   "source": [
    "trump1_content = read_csv_column('./trump/trump_10.csv', '微博正文')\n",
    "\n",
    "# unseen_document = []\n",
    "# for trump1_content in trump1_contents:\n",
    "#     unseen_document = unseen_document + trump1_content.split()\n",
    "unseen_document = []\n",
    "item = ''\n",
    "for i in range(len(trump1_content)):\n",
    "    item = item + trump1_content[i]\n",
    "unseen_document_raw = item.split()\n",
    "for i in unseen_document_raw:\n",
    "    if len(i) != 1:\n",
    "        unseen_document.append(i)\n",
    "\n",
    "bow_vector = dictionary.doc2bow(unseen_document)\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 20)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}